# Made by: Airil / Ainhoa

import re
import os
import requests
import subprocess
from subprocess import call
import ipaddress
import pythonping
import signal
import socket
import itertools
from multiprocessing.pool import ThreadPool

from termcolor import colored
from pwn import *

DN = open(os.devnull, 'w')
lock = threading.Lock()
stop_brute_force = False

def handle_signal(signal, frame):
    global stop_brute_force
    with lock:
        stop_brute_force = True
    print(colored("\n[!] Force brute stopped by user", 'red'))
    
def change_mac(net_interface):
    print(colored("\n[+]", 'green') + " Setting real MAC...")
    mac = ':'.join(['{:02x}'.format(random.randint(0, 255)) for _ in range(6)])
    call(["ifconfig", net_interface, "down"], stdout=DN, stderr=DN)
    call(["ifconfig", net_interface, "hw", "ether", mac])
    call(["ifconfig", net_interface, "up"], stdout=DN, stderr=DN)
    
    print(colored("[+]", 'green') + " New MAC: " + colored(mac, 'cyan'))

def port_scan(host, ports, protocolo):
    valid_ports = {}
    if ports == "":
        start_port, end_port = 1, 65535
    else:
        start_port, end_port = map(int, ports.split())
    
    p = log.progress("Scaning")
    
    for port in range(start_port, end_port+1):
        p.status(port)
        try:
            if protocolo == "tcp":
                s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            elif protocolo == "udp":
                s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            else:
                print(colored("\n[!] Invalid protocol", 'red'))
                return
            
            s.settimeout(0.3)
            resultado = s.connect_ex((host, port)) if protocolo == "tcp" else s.sendto(b"", (host, port))
            
            if resultado == 0:
                print(colored("[+]", 'green') + " Open port founded: " + colored(port, 'cyan'))
                
                if protocolo == "tcp":
                    # Fragmenta los paquetes TCP
                    s.sendall(b"GET / HTTP/1.1\r\n")
                    s.sendall(b"Host: example.com\r\n")
                    s.sendall(b"\r\n")

                    banner = s.recv(1024)
                    print(f"Banner: {banner.decode().strip()}")
                    
                service = socket.getservbyport(port, protocolo)
                valid_ports[port] = service if service else ""
            
            # Cierra el socket para que haga SYN --> SYN ACK --> RST en vez de ACK
            s.close()
            
        except socket.error:
            print(colored("\n[!] Error to connect"))
    
    p.status("Done!")

    return valid_ports

def scan_local_network(ipandcidr):
    print(colored("[+] Scanning localnet...", 'green'))
    network = ipaddress.ip_network(ipandcidr, strict=False)
    active_hosts = []

    for host in network.hosts():
        ip = str(host)
        try:
            response_list = pythonping.ping(ip, count=1, timeout=0.01)
            if str(response_list.rtt_avg_ms) != "10.0":
                active_hosts.append(ip)
        except pythonping.TimeoutException:
            pass

    return active_hosts

def check_subdomain(args):
    subdomain, domain, firsturl, p = args
    brute_force_subdomain = subdomain + '.' + domain
    url = firsturl + brute_force_subdomain
    try:
        p.status(subdomain)
        resp = requests.get(str(url))
        if resp.status_code < 400:
            print(colored("[+] Subdomain found: ", 'green') + colored(subdomain, 'blue'))
            return subdomain
    except:
        pass
    return ""

def subdomains(domain, brute, sslcert):
    subdomains = []
    # Abusando de la transparencia del ssl
    print(colored("[+] Searching for subdomains by leveraging SSL transparency (pasive method)...", 'green'))
    target = re.sub('.*www\.', '', domain, 1).split('/')[0].strip()
    if sslcert == "y" or sslcert == "yes":
        req = requests.get("https://crt.sh/?q=%.{d}&output=json".format(d=target))
    else:
        req = requests.get("http://crt.sh/?q=%.{d}&output=json".format(d=target))

    if req.status_code >= 400:
        print(colored("[!] ERROR: domain not found! check if its correct, internet conexion and restart this tool please", 'red'))
        return subdomains

    for (key, value) in enumerate(req.json()):
        subdomains.append(value['name_value'])
    
    # Con OSINT
    print(colored("[+] Searching for more subdomains with OSINT (pasive method)...", 'green'))
    
    # Falta por hacer esto, que pereza
    
    # Domain Zone Transfer
    print(colored("[+] Searching for more subdomains with Domain Zone Trasfere (active method)...", 'green'))

    ping_process = subprocess.Popen(['ping', '-c', '1', domain], stdout=subprocess.PIPE)
    output, _ = ping_process.communicate()

    ip_pattern = re.compile(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    match = ip_pattern.search(output.decode('utf-8'))
    
    ip = match.group(1)
    
    dig_process = subprocess.Popen(['dig', ip, 'axfr'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, error = dig_process.communicate()

    if b"; Transfer failed." in output:
        print(colored("[!] Domain Zone Trasfer failed!", 'red'))
    else:
        subdomain_pattern = re.compile(r'\b(?:[a-zA-Z0-9-]+\.)+' + re.escape(ip) + r'\b')
        subdomains.extend(subdomain_pattern.findall(output.decode('utf-8')))
    
    # Bruteforce
    signal.signal(signal.SIGINT, handle_signal)

    if sslcert == "y" or sslcert == "yes":
        firsturl = "https://"
    else:
        firsturl = "http://"

    if brute == "y" or brute == "yes":
        print(colored("[+] Starting fuzzing for subdomains...", 'green'))
        p = log.progress("Brute forcing")
        dictionary_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'subdomain.txt')
        with open(dictionary_file) as f:
            dictionary = f.read().splitlines()

        args = [(subdomain, domain, firsturl, p) for subdomain in dictionary]
        with ThreadPool(processes=20) as pool:
            for result in pool.imap_unordered(check_subdomain, args):
                if result != "":
                    subdomains.append(result)
                with lock:
                    if stop_brute_force:
                        pool.terminate()
                        break

        p.success("Brute force finished!")

    subdomains = sorted(set(subdomains))
    return subdomains

def extract_directories(url, content): # para sacar los directorios de robots.txt y sitemap.xml
    pattern = r"\/[\w\/.-]+\/"
    directories = re.findall(pattern, content)
    
    processed_directories = []
    for directory in directories:
        if directory.startswith(url):
            directory = directory[len(url):]
        
        if not directory.startswith("/"):
            directory = "/" + directory
        
        processed_directories.append(directory)
    
    return processed_directories

def check_url(args):
    url, word, p = args
    word = word.strip()
    try:
        p.status(word)
        resp = requests.get(url+word)
        if resp.status_code >= 200 and resp.status_code < 400:
            print(colored("[+] Directory found: ", 'green') + colored("/", 'cyan'), colored(word, 'cyan') + colored("  -->  Status code: ", 'green') + colored(resp.status_code, 'cyan'))
            return word
        else:
            return ""
    except:
        return ""

def dir_fuzzing(web):
    print(colored("[+] Finding directories...", 'green'))
    directories = []
    
    # PASIVE
    robots_url = web + "/robots.txt"
    response = requests.get(robots_url)
    if response.status_code == 200:
        print(colored("[+]", 'green') + colored(" robots.txt ", 'cyan') + colored("found!", 'green'))
        directories += extract_directories(web, response.text)
    else:
        print(colored("[!]", 'red') + colored(" robots.txt ", 'yellow') + colored("doesn't exist!", 'red'))
        
    sitemap_url = web + "/sitemap.xml"
    response = requests.get(sitemap_url)
    if response.status_code == 200:
        print(colored("[+]", 'green') + colored(" sitemap.xml ", 'cyan') + colored("found!", 'green'))
        directories += extract_directories(web, response.text)
    else:
        print(colored("[!]", 'red') + colored(" sitemap.xml ", 'yellow') + colored("doesn't exist!", 'red'))
    
    # ACTIVE
    signal.signal(signal.SIGINT, handle_signal)
    
    p = log.progress("Fuzzing")
    url = web+"/"
    with open("directory_list.txt", "r") as f:
        args = [(url, word, p) for word in f]
        with ThreadPool(processes=20) as pool:
            for result in pool.imap_unordered(check_url, args):
                if result != "":
                    directories.append(result)
                if stop_brute_force:
                    with lock:
                        pool.terminate()
                        break
    
    p.status("Done!")
    
    processed_directories = []
    for directory in directories:
        if directory.startswith("/" + web[8:]):
            continue
        if directory.startswith("//" + web[8:]):
            continue
        processed_directories.append(directory)
    
    processed_directories = set(processed_directories)
    
    return processed_directories
