# Made by: Airil / Ainhoa

import re
import os
import requests
import subprocess
from subprocess import call
import ipaddress
import pythonping
import signal
import socket
import xml.etree.ElementTree as ET
from multiprocessing.pool import ThreadPool
import whois

from termcolor import colored
from pwn import *

DN = open(os.devnull, 'w')
lock = threading.Lock()
stop_brute_force = False

def handle_signal(signal, frame):
    global stop_brute_force
    with lock:
        stop_brute_force = True
    print(colored("\n[!] Force brute stopped by user", 'red'))

def change_mac(net_interface):
    print(colored("\n[+]", 'green') + " Setting real MAC...")
    mac = ':'.join(['{:02x}'.format(random.randint(0, 255)) for _ in range(6)])
    call(["ifconfig", net_interface, "down"], stdout=DN, stderr=DN)
    call(["ifconfig", net_interface, "hw", "ether", mac])
    call(["ifconfig", net_interface, "up"], stdout=DN, stderr=DN)
    
    print(colored("[+]", 'green') + " New MAC: " + colored(mac, 'cyan'))

def get_whois_info(domain):
    try:
        w = whois.whois(domain)
        print(colored("\n DOMAIN INFORMATION:", 'green', attrs=['dark', 'underline']) +
                colored("\n  Domain Name:", 'green'), colored(w.domain_name, 'cyan') +
                colored("\n  Registrar:", 'green'), colored(w.registrar, 'cyan') +
                colored("\n  Creation Date:", 'green'), colored(w.creation_date, 'cyan') +
                colored("\n  Expiration Date:", 'green'), colored(w.expiration_date, 'cyan') +
                colored("\n  Updated Date:", 'green'), colored(w.updated_date, 'cyan') +
                colored("\n  Name Servers:", 'green'), colored(w.name_servers, 'cyan') +
                colored("\n  Status:", 'green'), colored(w.status, 'cyan') +
                colored("\n  Emails:", 'green'), colored(w.emails, 'cyan') +
                colored("\n  WHOIS Server:", 'green'), colored(w.whois_server, 'cyan') +
                colored("\n  Organization:", 'green'), colored(w.org, 'cyan') +
                colored("\n  Address:", 'green'), colored(w.address, 'cyan') +
                colored("\n  City:", 'green'), colored(w.city, 'cyan') +
                colored("\n  State:", 'green'), colored(w.state, 'cyan') +
                colored("\n  Country:", 'green'), colored(w.country, 'cyan') +
                colored("\n  Zip Code:", 'green'), colored(w.zipcode, 'cyan') +
                colored("\n  Phone:", 'green'), colored(w.phone, 'cyan'))
        
    except Exception as e:
        print(colored("\n[!]Error:", 'red'), colored(str(e), 'yellow'))

def check_port(host, port, protocolo):
    try:
        if protocolo == "tcp":
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        elif protocolo == "udp":
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        else:
            print(colored("\n[!] Invalid protocol", 'red'))
            return None
        
        s.settimeout(0.3)
        resultado = s.connect_ex((host, port)) if protocolo == "tcp" else s.sendto(b"", (host, port))
        
        if resultado == 0:
            print(colored("[+]", 'green') + " Open port founded: " + colored(port, 'cyan'))
            
            if protocolo == "tcp":
                # Fragmenta los paquetes TCP
                s.sendall(b"GET / HTTP/1.1\r\n")
                s.sendall(b"Host: example.com\r\n")
                s.sendall(b"\r\n")

                banner = s.recv(1024)
                print(f"Banner: {banner.decode().strip()}")
            
            service = socket.getservbyport(port, protocolo)
            return service if service else ""
        
        # Cierra el socket para que haga SYN --> SYN ACK --> RST en vez de ACK
        s.close()
        
    except socket.error:
        print(colored("\n[!] Error to connect"))

    return None

def port_scan(host, ports, protocolo):
    common_ports = [80, 443, 21, 22, 25, 23, 3389, 110, 445, 139, 143, 53, 135, 3306, 8080, 1723, 111, 995, 993, 5900, 1025, 587, 8888, 199, 1720, 465, 20, 115, 6660, 6669, 8443, 554, 3306, 4949, 1352, 1433, 3268, 5631, 5632, 7070, 3690, 79, 6699, 6698, 873, 2082, 2083, 6001, 6002, 989, 990]
    valid_ports = {}

    if ports == "all":
        start_port, end_port = 1, 65535
    elif ports == "":
        start_port, end_port = 1, 2
    else:
        start_port, end_port = map(int, ports.split())

    p = log.progress("Scaning")

    for port in common_ports:
        p.status(port)
        service = check_port(host, port, protocolo)
        if service:
            valid_ports[port] = service

    if start_port >= 1:
        for port in range(start_port, end_port + 1):
            p.status(port)
            if port not in common_ports:
                service = check_port(host, port, protocolo)
                if service:
                    valid_ports[port] = service

    p.status("Done!")
    
    return valid_ports

def scan_local_network(ipandcidr):
    print(colored("[+] Scanning localnet...", 'green'))
    network = ipaddress.ip_network(ipandcidr, strict=False)
    active_hosts = []

    for host in network.hosts():
        ip = str(host)
        try:
            response_list = pythonping.ping(ip, count=1, timeout=0.01)
            if str(response_list.rtt_avg_ms) != "10.0":
                active_hosts.append(ip)
        except pythonping.TimeoutException:
            pass

    return active_hosts

def check_subdomain(args):
    subdomain, domain, firsturl, p = args
    brute_force_subdomain = subdomain + '.' + domain
    url = firsturl + brute_force_subdomain
    try:
        p.status(subdomain)
        resp = requests.get(str(url))
        if resp.status_code < 400:
            print(colored("[+] Subdomain found: ", 'green') + colored(subdomain, 'blue'))
            return subdomain
    except:
        pass
    return ""

def subdomains(domain, brute, sslcert):
    subdomains = []
    # Abusando de la transparencia del ssl
    print(colored("[+] Searching for subdomains by leveraging SSL transparency (pasive method)...", 'green'))
    target = re.sub('.*www\.', '', domain, 1).split('/')[0].strip()
    if sslcert == "y" or sslcert == "yes":
        req = requests.get("https://crt.sh/?q=%.{d}&output=json".format(d=target))
    else:
        req = requests.get("http://crt.sh/?q=%.{d}&output=json".format(d=target))

    if req.status_code >= 400:
        print(colored("[!] ERROR: domain not found! check if its correct, internet conexion and restart this tool please", 'red'))
        return subdomains

    for (key, value) in enumerate(req.json()):
        subdomains.append(value['name_value'])
    
    # Con OSINT
    print(colored("[+] Searching for more subdomains with OSINT (pasive method)...", 'green'))
    
    # Falta por hacer esto, que pereza
    
    # Domain Zone Transfer
    print(colored("[+] Searching for more subdomains with Domain Zone Trasfere (active method)...", 'green'))

    ping_process = subprocess.Popen(['ping', '-c', '1', domain], stdout=subprocess.PIPE)
    output, _ = ping_process.communicate()

    ip_pattern = re.compile(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    match = ip_pattern.search(output.decode('utf-8'))
    
    ip = match.group(1)
    
    dig_process = subprocess.Popen(['dig', 'axfr', f'@{ip}', domain], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, error = dig_process.communicate()

    if b"; Transfer failed." in output:
        print(colored("[!] Domain Zone Trasfer failed!", 'red'))
    else:
        subdomain_pattern = re.compile(r'\b(?:[a-zA-Z0-9-]+\.)+' + re.escape(ip) + r'\b')
        subdomains.extend(subdomain_pattern.findall(output.decode('utf-8')))
    
    # Bruteforce
    signal.signal(signal.SIGINT, handle_signal)

    if sslcert == "y" or sslcert == "yes":
        firsturl = "https://"
    else:
        firsturl = "http://"

    if brute == "y" or brute == "yes":
        print(colored("[+] Starting fuzzing for subdomains...", 'green'))
        p = log.progress("Brute forcing")
        dictionary_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'subdomain.txt')
        with open(dictionary_file) as f:
            dictionary = f.read().splitlines()

        args = [(subdomain, domain, firsturl, p) for subdomain in dictionary]
        with ThreadPool(processes=100) as pool:
            for result in pool.imap_unordered(check_subdomain, args):
                if result != "":
                    subdomains.append(result)
                with lock:
                    if stop_brute_force:
                        pool.terminate()
                        break

        p.success("Brute force finished!")

    subdomains = sorted(set(subdomains))
    return subdomains

def extract_directories(url, content): # para sacar los directorios de robots.txt y sitemap.xml
    pattern = r"\/[\w\/.-]+\/"
    directories = re.findall(pattern, content)
    
    processed_directories = []
    for directory in directories:
        if directory.startswith(url):
            directory = directory[len(url):]
        
        if not directory.startswith("/"):
            directory = "/" + directory
        
        processed_directories.append(directory)
    
    return processed_directories

def check_url(args):
    url, word, p, hc = args
    word = word.strip()
    try:
        p.status(word)
        resp = requests.get(url + word, allow_redirects=False)
        
        if int(resp.status_code) != 404 and int(resp.status_code) not in hc:
            print(colored("[+] Directory found: ", 'green') + colored("/", 'cyan') + colored(word, 'cyan') + colored("  -->  Status code: ", 'green') + colored(resp.status_code, 'cyan'))
            return word
        else:
            return ""
    except:
        return ""

def dir_fuzzing(web, hc):
    print(colored("[+] Finding directories...", 'green'))
    directories = []
    
    # PASIVE
    robots_url = web + "/robots.txt"
    response = requests.get(robots_url)
    if response.status_code == 200:
        print(colored("[+]", 'green') + colored(" robots.txt ", 'cyan') + colored("found!", 'green'))
        directories += extract_directories(web, response.text)
        
    sitemap_url = web + "/sitemap.xml"
    response = requests.get(sitemap_url)
    if response.status_code == 200:
        print(colored("[+]", 'green') + colored(" sitemap.xml ", 'cyan') + colored("found!", 'green'))
        directories += extract_directories(web, response.text)
    
    # ACTIVE
    signal.signal(signal.SIGINT, handle_signal)
    
    p = log.progress("Fuzzing")
    if web[-1] != '/':
        web = web+"/"

    with open("directory_list.txt", "r") as f:
        args = [(web, word, p, hc) for word in f]
        with ThreadPool(processes=100) as pool:
            for result in pool.imap_unordered(check_url, args):
                if result != "":
                    directories.append(result)
                if stop_brute_force:
                    with lock:
                        pool.terminate()
                        break
    
    p.status("Done!")
    
    processed_directories = []
    for directory in directories:
        if directory.startswith("/" + web[8:]):
            continue
        if directory.startswith("//" + web[8:]):
            continue
        processed_directories.append(directory)
    
    processed_directories = set(processed_directories)
    
    return processed_directories

def check_url2(args):
    url, word, p, hc = args
    word = word.strip()
    try:
        p.status(word)
        resp = requests.get(url + word, allow_redirects=False)
        
        if int(resp.status_code) != 404 and str(resp.status_code) not in hc:
            return word
        else:
            return ""
    except:
        return ""

def directory_map(url, thread_num, hc, path, p=None, wordlist="directory_list.txt"):
    extensions = ['.js', '.php', '.html', '.css', '.txt', '.py', '.img', '.jpg']
    signal.signal(signal.SIGINT, handle_signal)

    if path == 0:
        print(colored("\nDIRECTORY MAP:", 'green', attrs=['dark', 'underline']))
        p = log.progress("Fuzzing")
    
    url = url if url[-1] == '/' else url + '/'
    
    directories = []
    with open(wordlist, "r") as f:
        args = [(url, word, p, hc) for word in f]
        args2 = []
        
        with open("reducted_dirs.txt", "r") as f:
            ags = [(url, word, p, hc) for word in f]
            for i in ags:
                args2.append((i[0], i[1].strip(), i[2], i[3]))
                for a in extensions:
                    args2.append((i[0], str(i[1].strip()+a), i[2], i[3]))
        
        for i in args:
            args2.append((i[0], i[1].strip(), i[2], i[3]))
            for a in extensions:
                args2.append((i[0], str(i[1].strip()+a), i[2], i[3]))

        with ThreadPool(processes=int(thread_num)) as pool:
            for result in pool.imap_unordered(check_url2, args2):
                if result != "":
                    directories.append(result)
                    espacio = " " * 4 * path # y tiempo, no te jode XD
                    codigolioco = requests.get(url + result, allow_redirects=False).status_code

                    if path == 0:
                        print("\n/" + str(result) + colored(str(" --> " + str(codigolioco)), 'cyan'))
                    else:
                        print(espacio + "/" + str(result) + colored(str(" --> " + str(codigolioco)), 'cyan'))

                    if "." not in result:
                        directory_map(url + result, thread_num, hc, path+1, p, wordlist="reducted_dirs.txt")
                
                if stop_brute_force:
                    with lock:
                        pool.terminate()
                        break

    p.status("Done!")

def tec_enum(url):
    print(colored("\nWEB TECNOLOGIES:", 'green', attrs=['dark', 'underline']))
    whatweb_output = subprocess.check_output(['whatweb', url]).decode('utf-8')
    tecnologias = whatweb_output.split(',')
    tecnologias = [line.strip(',') for line in tecnologias]

    for tecnologia in tecnologias:
        searchsploit_output = subprocess.check_output(['searchsploit', tecnologia]).decode('utf-8')
        print(colored("Â· ", 'green'), colored(tecnologia, 'green'))
        if searchsploit_output and  "No Results" not in searchsploit_output:
            print(colored("  Exploit found: ", 'red'), colored(searchsploit_output, 'yellow'))

def webdav_enum(url, depth=1, username=None, password=None):
    try:
        auth = None
        if username and password:
            auth = (username, password)

        try:
            response = requests.options(url, auth=auth)
            if 'allow' in response.headers:
                methods = response.headers['allow']
                print(str(colored("[+] Allowed methods: ", 'green') + colored(methods, 'cyan')))
            else:
                print(colored("[!] Unable to determine allowed methods.", 'red'))
        except Exception as e:
            print(str(colored("[!] Error fetching options: ", 'green') + colored(e, 'cyan')))
            return
        
        if 'PROPFIND' in methods:
            headers = {
                'Depth': str(depth),
                'Content-Type': 'application/xml'
            }
            body = '<?xml version="1.0"?><a:propfind xmlns:a="DAV:"><a:allprop/></a:propfind>'
            try:
                response = requests.request('PROPFIND', url, headers=headers, data=body, auth=auth)
                if response.status_code == 207:
                    print_resources(response.content)
            except Exception as e:
                print(str(colored("[!] Error fetching resources with PROPFIND: ", 'red') + colored(e, 'yellow')))
    except:
        pass
    
def print_resources(response_content):
    ns = {'D': 'DAV:'}
    tree = ET.fromstring(response_content)
    for response in tree.findall('D:response', ns):
        href = response.find('D:href', ns)
        if href is not None:
            print(str(colored("[+] Resources: ", 'green') + colored(href.text, 'cyan')))
